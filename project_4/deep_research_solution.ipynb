{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe0fb30d",
   "metadata": {},
   "source": [
    "# Project 4: **Build a Deep Research System**\n",
    "Welcome to project 4! For this project, we shift our focus from tool use and agents to *reasoning* models. You will practice state‑of‑the‑art inference‑time scaling methods such as *Chain‑of‑Thought* prompting and *Tree‑of‑Thoughts*, and briefly explore high-levels of training reasoning models using techniques like **STaR**.\n",
    "\n",
    "\n",
    "Finally, you will put everything together to build a *deep research agent* that can browse the web, reason over what it finds, and give structured answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54845369",
   "metadata": {},
   "source": [
    "## Learning Objectives  \n",
    "* Apply common inference‑time scaling methods: **zero‑shot / few‑shot CoT, self‑consistency, sequential decoding, tree‑of‑thoughts**  \n",
    "* Gain intuition for **training** reasoning‑capable models following **STaR** approach \n",
    "* Build a minimal **deep‑research agent** that combines step‑by‑step reasoning with live web search   \n",
    "* Practice extending deep-search to a multi-agent system "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a40a86",
   "metadata": {},
   "source": [
    "## Roadmap  \n",
    "1. Environment setup  \n",
    "2. Inference‑time scaling  \n",
    "   2.1 Few‑shot & zero‑shot CoT  \n",
    "   2.2 Self‑consistency\n",
    "   2.3 Sequential revisions  \n",
    "   2.4 Tree‑of‑Thought\n",
    "3. STaR for training models for reasoning  \n",
    "4. Deep-research agent  \n",
    "5. (Optional) Multi-agent deep-research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e480f76",
   "metadata": {},
   "source": [
    "# 1‑ Environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c2218",
   "metadata": {},
   "source": [
    "## 1.1- Conda environment\n",
    "\n",
    "Before we start coding, you need a reproducible setup. Open a terminal in the same directory as this notebook and run:\n",
    "\n",
    "```bash\n",
    "# Create and activate the conda environment\n",
    "conda env create -f environment.yaml && conda activate deep_research\n",
    "\n",
    "# Register this environment as a Jupyter kernel\n",
    "python -m ipykernel install --user --name=deep_research --display-name \"deep_research\"\n",
    "```\n",
    "Once this is done, you can select \"deep_research\" from the Kernel → Change Kernel menu in Jupyter or VS Code.\n",
    "\n",
    "## 1.2 Ollama setup\n",
    "\n",
    "In this project we use the `llama3.2:3b` and `deepseek-r1:8b` models. You can try other smaller or larger reasoning LLMs such as `qwen2.5:3b-instruct` or `phi4-mini` to compare performance. Explore available models here: https://ollama.com/library.\n",
    "\n",
    "```bash\n",
    "ollama pull llama3.2:3b\n",
    "ollama pull deepseek-r1:8b\n",
    "# Additional small reasoning models to compare\n",
    "# ollama pull qwen2.5:3b-instruct\n",
    "# ollama pull phi4-mini\n",
    "\n",
    "```\n",
    "\n",
    "`ollama pull` downloads the model so you can run it locally without API calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e8d1b7",
   "metadata": {},
   "source": [
    "---  \n",
    "# 2‑ Inference‑time scaling\n",
    "\n",
    "Inference-time scaling refers to techniques that make an existing model reason better without retraining it. Instead of changing the model’s weights, we achieve reasoning capability by adjusting how we prompt, sample, or aggregate LLM's outputs.\n",
    "\n",
    "In this section, we’ll explore several inference-time strategies that improve reasoning quality using a non-reasoning base model. You will experiment with and compare methods such as:\n",
    "\n",
    "- Few-shot Chain-of-Thought (CoT)\n",
    "- Zero-shot CoT\n",
    "- Self-consistency\n",
    "- Sequential revision\n",
    "- Tree-of-Thoughts (ToT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d499a",
   "metadata": {},
   "source": [
    "### 2.1: Few‑Shot CoT\n",
    "Few-shot prompting helps a model reason by showing one or multiple examples before asking a new question. By observing the pattern of reasoning and final answers, the model learns how to structure its own reasoning process on the new input.\n",
    "\n",
    "In this exercise, you will create a prompt that includes a few example Q&A pairs demonstrating step-by-step reasoning. Then, you will feed a new question and see the model’s output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "173d73f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the length, we need to use the formula for the perimeter of a rectangle:\n",
      "\n",
      "Perimeter = 2(Length + Width)\n",
      "\n",
      "We are given the perimeter (40 cm) and the width (5 cm), so we can plug these values into the formula:\n",
      "\n",
      "40 = 2(Length + 5)\n",
      "\n",
      "First, divide both sides by 2:\n",
      "\n",
      "20 = Length + 5\n",
      "\n",
      "Next, subtract 5 from both sides:\n",
      "\n",
      "15 = Length\n",
      "\n",
      "Therefore, the length of the rectangle is 15 cm.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Write a few examples showing reasoning steps\n",
    "# Step 2: Write your new question\n",
    "# Step 3: Concatenate examples + new question into a single prompt\n",
    "# Step 4: Call your Ollama or OpenAI client to get a response from llama3.2:3b # e.g., client.chat.completions.create(...)\n",
    "# Step 5: Print the final answer\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key = \"ollama\", base_url = \"http://localhost:11434/v1\")\n",
    "\n",
    "few_shot_examples = \"\"\"Q: If it is 3 PM in London (UTC+0), what time is it in New York (UTC-5)?\n",
    "A: London is 5 hours ahead, so we subtract 5. The final answer is 10 AM.\n",
    "\n",
    "Q: A tank holds 60 L of water. It leaks 3 L per hour and is filled at 5 L per hour. How much water after 4 h?\n",
    "A: Net fill = 5-3 = 2 L/h. 2x4 = 8 L. The final answer is 68 L.\n",
    "\"\"\"\n",
    "\n",
    "question = \"A rectangle has perimeter 40 cm and width 5 cm. What is its length?\"\n",
    "prompt = few_shot_examples + f\"Q: {question} A:\"\n",
    "\n",
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\":\"user\",\"content\": prompt}],\n",
    "    temperature=0.9\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698e29d9",
   "metadata": {},
   "source": [
    "### (Optional) Few-shot CoT on GPT2\n",
    "GPT-2 is a pre-trained language model without instruction tuning. It continues text rather than answering questions. In this section, you'll try the exact same CoT pattern on GPT-2 and observe what happens. The goal is to test whether few-shot CoT alone can elicit structured reasoning from a non-chat LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8af711f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87d469c8cb947658312a60f1c9b0640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cmiyachi\\AppData\\Local\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\cmiyachi\\.cache\\huggingface\\hub\\models--openai-community--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb72ca98fd03499eb8a3b63253fb5f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb1193e068940ae8f67f708781da8e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486ea6d8da944620ba81eecb57747b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1626a8d001674eed8ba6c878af899330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a553de89592491c8ed9ca5397c93f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9628d7efc2264a84b8da3e77a986f842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy decoding:\n",
      " Q: If it is 3 PM in London (UTC+0), what time is it in New York (UTC-5)?\n",
      "A: London is 5 hours ahead, so we subtract 5. The final answer is 10 AM.\n",
      "\n",
      "Q: A tank holds 60 L of water. It leaks 3 L per hour and is filled at 5 L per hour. How much water after 4 h?\n",
      "A: Net fill = 5-3 = 2 L/h. 2x4 = 8 L. The final answer is 68 L.\n",
      "Q: A rectangle has perimeter 40 cm and width 5 cm. What is its length?\n",
      "A: The rectangle is 40 cm x 5 cm.\n",
      "\n",
      "Q: A rectangle has perimeter 40 cm and width 5 cm. What is its length?\n",
      "\n",
      "A: The rectangle is 40 cm x 5 cm.\n",
      "\n",
      "Q: A rectangle has perimeter 40 cm and width 5 cm. What is its length?\n",
      "\n",
      "A: The rectangle is 40 cm x 5 cm.\n",
      "\n",
      "Q: A rectangle has perimeter 40 cm and width 5 cm. What is its length?\n",
      "\n",
      "A: The rectangle is 40 cm x 5 cm.\n",
      "\n",
      "Q: A rectangle has perimeter 40 cm and width 5 cm. What is its length?\n",
      "\n",
      "Sampled decoding:\n",
      " Q: If it is 3 PM in London (UTC+0), what time is it in New York (UTC-5)?\n",
      "A: London is 5 hours ahead, so we subtract 5. The final answer is 10 AM.\n",
      "\n",
      "Q: A tank holds 60 L of water. It leaks 3 L per hour and is filled at 5 L per hour. How much water after 4 h?\n",
      "A: Net fill = 5-3 = 2 L/h. 2x4 = 8 L. The final answer is 68 L.\n",
      "Q: A rectangle has perimeter 40 cm and width 5 cm. What is its length?\n",
      "A: The diameter of a rectangle is 0.1 mm.\n",
      "\n",
      "Q: A rectangle has perimeter 3.5 cm. What is its width?\n",
      "\n",
      "A: The diameter of a rectangle is 2.5 mm.\n",
      "\n",
      "Q: A rectangle has perimeter 3.5 cm. What is its width?\n",
      "\n",
      "A: The diameter of a rectangle is 3.5 cm.\n",
      "\n",
      "Q: A rectangle has perimeter 1.5 cm. What is its height?\n",
      "\n",
      "A: The height of a rectangle is 5.25 cm.\n",
      "\n",
      "Q: A rectangle has perimeter 2.5 cm. What is its width?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Step 1: Load GPT-2 text-generation from huggingface (https://huggingface.co/docs/transformers/en/model_doc/gpt2)\n",
    "# Step 2: Write 1–2 few-shot reasoning examples (short, explicit steps + final answer in your own unique format)\n",
    "# Step 3: Append a new test question after the examples to form one prompt string\n",
    "# Step 4: Generate 1–3 completions with different decoding settings (e.g., greedy vs. top-k)\n",
    "# Step 5: Print raw outputs; check if steps are followed and if the final answer is correct\n",
    "\n",
    "# Device selection: use CUDA if available, otherwise CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA (GPU)\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Apple Silicon)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "generator = pipeline(task=\"text-generation\", model=\"openai-community/gpt2\", device=device)\n",
    "\n",
    "few_shot = \"\"\"Q: If it is 3 PM in London (UTC+0), what time is it in New York (UTC-5)?\n",
    "A: London is 5 hours ahead, so we subtract 5. The final answer is 10 AM.\n",
    "\n",
    "Q: A tank holds 60 L of water. It leaks 3 L per hour and is filled at 5 L per hour. How much water after 4 h?\n",
    "A: Net fill = 5-3 = 2 L/h. 2x4 = 8 L. The final answer is 68 L.\n",
    "\"\"\"\n",
    "\n",
    "q = \"A rectangle has perimeter 40 cm and width 5 cm. What is its length?\"\n",
    "prompt = few_shot + f\"Q: {q}\\nA:\"\n",
    "\n",
    "# # Greedy\n",
    "out_greedy = generator(\n",
    "    prompt,\n",
    "    max_new_tokens=128,\n",
    "    do_sample=False,\n",
    "    use_cache=False\n",
    ")[0][\"generated_text\"]\n",
    "\n",
    "out_sample = generator(\n",
    "    prompt,\n",
    "    max_new_tokens=128,\n",
    "    do_sample=True,\n",
    "    top_p=0.9,\n",
    "    temperature=0.8,\n",
    "    use_cache=False\n",
    ")[0][\"generated_text\"]\n",
    "\n",
    "print(\"Greedy decoding:\\n\", out_greedy)\n",
    "print(\"\\nSampled decoding:\\n\", out_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adee0e7",
   "metadata": {},
   "source": [
    "### 2.2: Zero‑Shot Chain‑of‑Thought\n",
    "Zero-shot CoT encourages the model to reason without examples by adding a short cue such as “Let’s think step by step.” This simple phrase often activates the model’s latent reasoning ability even when no demonstrations are provided. It serves as a baseline to compare with few-shot and other inference-time scaling methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c444eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To understand why neural networks are used to build Large Language Models (LLMs), let's break down the process step by step:\n",
      "\n",
      "1. **Understanding the Problem**: The primary goal of building an LLM is to create a model that can generate human-like text, answer questions, or perform other natural language processing tasks.\n",
      "\n",
      "2. **Traditional Approaches**: Before neural networks, traditional approaches to NLP involved rule-based systems and statistical models. These methods were limited in their ability to handle complex linguistic structures and nuances of human language.\n",
      "\n",
      "3. **The Rise of Neural Networks**: In the 1980s and 1990s, researchers began exploring the use of neural networks for NLP tasks. The key innovation was the development of recurrent neural networks (RNNs) and long short-term memory (LSTM) networks, which allowed models to capture sequential dependencies in language.\n",
      "\n",
      "4. **Why Neural Networks?**: Neural networks are particularly well-suited for LLMs because they can:\n",
      "   - Learn complex patterns in language data\n",
      "   - Handle sequential dependencies between words or tokens\n",
      "   - Capture contextual relationships and nuances of human language\n",
      "\n",
      "5. **Key Architectures**: The most common architectures used in LLMs are:\n",
      "   - Recurrent Neural Networks (RNNs)\n",
      "   - Long Short-Term Memory (LSTM) networks\n",
      "   - Transformers, which have become the de facto standard for modern LLMs\n",
      "\n",
      "6. **Why Transformers?**: Transformers revolutionized the field of NLP by introducing self-attention mechanisms, which allow models to weigh the importance of different tokens in a sentence relative to each other. This leads to better performance and more efficient training.\n",
      "\n",
      "7. **Training Large Models**: The availability of large amounts of labeled data (e.g., text corpora) has enabled researchers to train massive neural networks that can capture complex patterns in language. These models are often trained using techniques like masked language modeling, next sentence prediction, or other supervised learning objectives.\n",
      "\n",
      "8. **Advantages of Neural Networks**: The use of neural networks for LLMs offers several advantages:\n",
      "   - Ability to learn from large amounts of data\n",
      "   - Flexibility and adaptability in handling different linguistic tasks\n",
      "   - Potential for significant improvements over traditional NLP approaches\n",
      "\n",
      "In summary, the use of neural networks for building LLMs is driven by their ability to capture complex patterns in language, handle sequential dependencies, and learn from large amounts of data. The development of architectures like RNNs, LSTMs, and transformers has further enabled the creation of powerful models that can generate human-like text or perform other NLP tasks with high accuracy.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Step 1: Write the question and a zero-shot CoT cue (e.g., \"Let's think step by step.\")\n",
    "# Step 2: Build a single prompt string that includes brief role guidance plus the question\n",
    "# Step 3: Call your Ollama or OpenAI client to get a response from llama3.2:3b  # e.g., client.chat.completions.create(...)\n",
    "# Step 4: Print the chain and the final answer\n",
    "\n",
    "client = OpenAI(api_key = \"ollama\", base_url = \"http://localhost:11434/v1\")\n",
    "\n",
    "question = \"Why do we use neural network to build LLMs?\"\n",
    "\n",
    "prompt = f\"\"\"You are a knowledgeable tutor. Answer the question. \n",
    "Question: {question}\n",
    "Let's think step by step.\"\"\"\n",
    "\n",
    "MODEL = \"llama3.2:3b\"\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\":\"user\",\"content\": prompt}],\n",
    "    temperature=0\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686708da",
   "metadata": {},
   "source": [
    "### 2.3 Self‑Consistency\n",
    "Self-consistency enhances reasoning accuracy by sampling multiple independent reasoning paths for the same question instead of relying on a single deterministic answer. Each run may follow a slightly different logical chain, and the diversity helps correct individual mistakes. After generating several reasoning traces, you then aggregate the final answers using majority voting.\n",
    "\n",
    "This approach is especially useful when tasks involve multi-step reasoning or arithmetic, where single-path outputs may be incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e2fb325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Votes: Counter({'**The square root of 144 is 12**.': 1, '**The square root of 144 is 12.**': 1, '**the square root of 144 is 12**.': 1, '.': 1, ': (√144)^2 = 144': 1})\n",
      "Chosen answer: **The square root of 144 is 12**.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import re, collections\n",
    "\n",
    "client = OpenAI(api_key = \"ollama\", base_url = \"http://localhost:11434/v1\")\n",
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "\n",
    "def cot_answer(question, temperature=1.3):\n",
    "    prompt = f\"\"\"Answer the following question with step-by-step reasoning and final answer after **Therefore,**.\n",
    "        Question: {question}\n",
    "        Let's think step by step.\"\"\"\n",
    "    \n",
    "    r = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\":\"user\",\"content\": prompt}],\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    content = r.choices[0].message.content\n",
    "    match = re.search(r\"[Tt]herefore,?\\s*(.*)\", content) # extract text after 'Therefore'.\n",
    "    return content, match.group(1).strip() if match else None\n",
    "\n",
    "\n",
    "def self_consistent(question, n=5):\n",
    "    answers = []\n",
    "    for _ in range(n):\n",
    "        _, ans = cot_answer(question, temperature=0.9)\n",
    "        answers.append(ans)\n",
    "    counter = collections.Counter(answers)\n",
    "    winner, _ = counter.most_common(1)[0]\n",
    "    return winner, counter\n",
    "\n",
    "\n",
    "question = \"What is the square root of 144?\"\n",
    "winner, counter = self_consistent(question)\n",
    "print(\"Votes:\", counter)\n",
    "print(\"Chosen answer:\", winner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bea715",
   "metadata": {},
   "source": [
    "### 2.4: Sequential Revision\n",
    "\n",
    "Sequential revision iteratively improves an answer by generating a first draft, critiquing it, and producing revised drafts that condition on prior answers. Each round should be short and focused, so improvements accumulate without drifting from the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07e5859d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draft 1: To solve this problem, let's start by using the information that the rectangle is twice as long as it is wide. If we call the width \"w\", then the length would be \"2w\". \n",
      "\n",
      "The perimeter of a rectangle is given by the formula: Perimeter = 2(Length + Width)\n",
      "We know the perimeter is 30 cm, so we can set up an equation:\n",
      "\n",
      "30 = 2(2w + w)\n",
      "\n",
      "Simplifying the equation:\n",
      "\n",
      "30 = 6w\n",
      "\n",
      "Dividing both sides by 6:\n",
      "\n",
      "5 = w\n",
      "\n",
      "So, the width of the rectangle is 5 cm.\n",
      "\n",
      "Now that we have the width, we can find the length:\n",
      "\n",
      "Length = 2w\n",
      "= 2 * 5\n",
      "= 10 cm\n",
      "\n",
      "The area of a rectangle is given by the formula: Area = Length x Width\n",
      "Substituting the values we found:\n",
      "\n",
      "Area = 10 x 5\n",
      "= 50 square centimeters.\n",
      "\n",
      "So, the area of the rectangle is 50 square centimeters.\n",
      "Draft 2: To find the area of a rectangle that has twice its width as length and a perimeter of 30 cm, we need to determine the dimensions of the rectangle.\n",
      "\n",
      "Let's denote the width as \"w\". Since the length is twice the width, the length can be represented by \"2w\".\n",
      "\n",
      "The formula for the perimeter of a rectangle is: Perimeter = 2(Length + Width). Given that the perimeter is 30 cm, we set up an equation:\n",
      "\n",
      "30 = 2(2w + w)\n",
      "\n",
      "Combine like terms:\n",
      "30 = 6w\n",
      "\n",
      "Divide both sides by 6 to solve for \"w\":\n",
      "5 = w\n",
      "\n",
      "Now that we have found the width (w = 5 cm), we can calculate the length:\n",
      "Length = 2w\n",
      "= 2 * 5\n",
      "= 10 cm\n",
      "\n",
      "With the length and width known, we can find the area using the formula: Area = Length x Width\n",
      "Area = 10 x 5\n",
      "= 50 square centimeters.\n",
      "Draft 2: To find the area of a rectangle that has twice its width as length and a perimeter of 30 cm, we need to determine the dimensions of the rectangle.\n",
      "\n",
      "Let's denote the width as \"w\". Since the length is twice the width, the length can be represented by \"2w\".\n",
      "\n",
      "The formula for the perimeter of a rectangle is: Perimeter = 2(Length + Width). Given that the perimeter is 30 cm, we set up an equation:\n",
      "\n",
      "30 = 2(2w + w)\n",
      "\n",
      "Combine like terms:\n",
      "30 = 6w\n",
      "\n",
      "Divide both sides by 6 to solve for \"w\":\n",
      "5 = w\n",
      "\n",
      "Now that we have found the width (w = 5 cm), we can calculate the length:\n",
      "Length = 2w\n",
      "= 2 * 5\n",
      "= 10 cm\n",
      "\n",
      "With the length and width known, we can find the area using the formula: Area = Length x Width\n",
      "Area = 10 x 5\n",
      "= 50 square centimeters.\n",
      "Draft 3: To solve for the area of a rectangle that has twice its width as length and a perimeter of 30 cm, we can break down the problem step by step.\n",
      "\n",
      "First, let's express the relationship between the length and the width algebraically. Let \"w\" represent the width, then the length is represented by \"2w\".\n",
      "\n",
      "The formula for the perimeter of a rectangle is: Perimeter = 2(Length + Width). We are given that the perimeter is 30 cm, so we can set up an equation:\n",
      "\n",
      "30 = 2(2w + w)\n",
      "\n",
      "Now, simplify and solve for \"w\": \n",
      "30 = 6w\n",
      "5 = w\n",
      "\n",
      "Since \"w\" represents the width, which is now known to be 5 cm. To find the length, multiply \"w\" by 2:\n",
      "Length = 2w\n",
      "= 2 * 5\n",
      "= 10 cm\n",
      "\n",
      "Now that we have determined the dimensions of the rectangle (width = 5 cm and length = 10 cm), we can calculate its area using the formula: Area = Length x Width\n",
      "Area = 10 x 5\n",
      "= 50 square centimeters.\n",
      "Draft 3: To solve for the area of a rectangle that has twice its width as length and a perimeter of 30 cm, we can break down the problem step by step.\n",
      "\n",
      "First, let's express the relationship between the length and the width algebraically. Let \"w\" represent the width, then the length is represented by \"2w\".\n",
      "\n",
      "The formula for the perimeter of a rectangle is: Perimeter = 2(Length + Width). We are given that the perimeter is 30 cm, so we can set up an equation:\n",
      "\n",
      "30 = 2(2w + w)\n",
      "\n",
      "Now, simplify and solve for \"w\": \n",
      "30 = 6w\n",
      "5 = w\n",
      "\n",
      "Since \"w\" represents the width, which is now known to be 5 cm. To find the length, multiply \"w\" by 2:\n",
      "Length = 2w\n",
      "= 2 * 5\n",
      "= 10 cm\n",
      "\n",
      "Now that we have determined the dimensions of the rectangle (width = 5 cm and length = 10 cm), we can calculate its area using the formula: Area = Length x Width\n",
      "Area = 10 x 5\n",
      "= 50 square centimeters.\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "\n",
    "def sequential_revision(question: str, max_steps: int = 3) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Keep your answers clear and correct.\"},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "   \n",
    "    draft = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "    ).choices[0].message.content.strip()\n",
    "    print(f\"Draft 1: {draft}\")\n",
    "\n",
    "    # Iterative revision\n",
    "    for idx in range(1, max_steps):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Improve answers by making them clearer and more accurate.\"},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "            {\"role\": \"assistant\", \"content\": draft},\n",
    "            {\"role\": \"user\", \"content\": \"Please revise your answer. Make it clearer, more accurate, and better written. Only include the new answer.\"}\n",
    "        ]\n",
    "        draft = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            temperature=0.7,\n",
    "        ).choices[0].message.content.strip()\n",
    "        print(f\"Draft {idx+1}: {draft}\")\n",
    "\n",
    "    return draft\n",
    "\n",
    "\n",
    "output = sequential_revision(\"If a rectangle is twice as long as it is wide and the perimeter is 30 cm, what is the area?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9319ee8",
   "metadata": {},
   "source": [
    "### 2.5 Tree‑of‑Thoughts\n",
    "Tree-of-Thoughts reframes reasoning as a search process rather than a single forward chain.\n",
    "Instead of producing one linear sequence of thoughts, the model generates multiple candidate thoughts at each step, evaluates their promise, and then expands only the best few. This allows exploration of different reasoning paths before committing to a final answer, similar to how humans brainstorm, prune, and refine ideas.\n",
    "\n",
    "\n",
    "In this section, you’ll experiment with two simplified versions of ToT:\n",
    "1. Word Ladder puzzle solver: a small example where each “thought” is a candidate word transition.\n",
    "2. Generic ToT search (depth 2, width 2): a minimal logic to expand, evaluate, and select reasoning branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d047801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hit', 'hot', 'dot', 'dog', 'cog']\n"
     ]
    }
   ],
   "source": [
    "###### Word Ladder Puzzle ##########\n",
    "\n",
    "def neighbors(word, vocabulary):\n",
    "    for i, c1 in enumerate(word):\n",
    "        for c2 in 'abcdefghijklmnopqrstuvwxyz':\n",
    "            if c1 != c2:\n",
    "                candidate = word[:i] + c2 + word[i+1:]\n",
    "                if candidate in vocabulary:\n",
    "                    yield candidate\n",
    "\n",
    "\n",
    "def tree_of_thought(start, goal, vocab, max_depth=5, beam_width=4):\n",
    "    frontier = [[start]]\n",
    "    for depth in range(max_depth):\n",
    "        candidates = []\n",
    "        for path in frontier:\n",
    "            for nxt in neighbors(path[-1], vocab):\n",
    "                if nxt in path:  # avoid loops\n",
    "                    continue\n",
    "                candidates.append(path + [nxt])\n",
    "        # score: negative edit distance to goal\n",
    "        scored = sorted(candidates, key=lambda p: sum(a!=b for a,b in zip(p[-1], goal)))\n",
    "        frontier = scored[:beam_width]\n",
    "        if any(p[-1] == goal for p in frontier):\n",
    "            return [p for p in frontier if p[-1]==goal][0]\n",
    "    return None\n",
    "\n",
    "\n",
    "vocab = {\"hit\",\"dot\",\"cog\",\"log\",\"dog\",\"lot\",\"lit\",\"hot\"}\n",
    "print(tree_of_thought(\"hit\", \"cog\", vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89067302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution (score 6):\n",
      "Based on the problem, here are two possible next thoughts:\n",
      "\n",
      "1. **Identify the Workshop Objective and Outcomes**: Before designing the workshop, it's essential to determine what students will learn or achieve. This could be a specific scientific concept, skill, or set of skills that aligns with their age group and interests. Some questions to consider include:\n",
      "   - What hands-on activities would stimulate learning in 12-year-olds?\n",
      "   - Are there any national or international standards for science education at this age level?\n",
      "   - How can we make the workshop engaging while ensuring it remains within a set time frame (e.g., 2 days, 3 hours/day)?\n",
      "\n",
      "This step will help clarify the scope and goals of the workshop.\n",
      "\n",
      "2. **Choose Materials and Equipment**: Selecting materials and equipment suitable for 12-year-olds is crucial for safety, effectiveness, and engagement. Some considerations include:\n",
      "   - What everyday materials or science kits are readily available or can be easily sourced for the activity?\n",
      "   - Do we need to purchase specific equipment, such as microscopes or tools for experiments?\n",
      "   - How will we ensure that all materials meet necessary health and safety standards?\n",
      "\n",
      "This step focuses on ensuring the feasibility of implementing the workshop plan with the resources made available.\n",
      "Here are two possible next thoughts based on the current partial solution:\n",
      "\n",
      "1. **Develop a Curriculum and Lesson Plan**: With the objective and outcomes in mind, it's time to create a structured lesson plan that outlines the specific activities, experiments, and topics covered during the workshop. This will help ensure that students learn something new and engaging while still meeting the overall objectives.\n",
      "\n",
      "Consider creating a detailed schedule for each day, including setup, introduction, activity sessions, and wrap-up. You can also include space for notes, discussions, and questions to encourage student participation and learning. Additionally, consider involving experts or facilitators who have experience working with 12-year-olds in science education.\n",
      "\n",
      "Some potential considerations for the lesson plan:\n",
      "\n",
      "* Aligning with national or international standards for science education\n",
      "* Incorporating hands-on activities, simulations, and real-world examples to engage students\n",
      "* Providing opportunities for questioning, discussion, and reflection throughout the workshop\n",
      "* Integrating technology, such as videos, apps, or online resources, to enhance learning\n",
      "\n",
      "2. **Consider Logistics and Equipment Maintenance**: Before the workshop begins, it's essential to ensure that you have all the necessary equipment, materials, and facilities in place.\n",
      "\n",
      "Some potential considerations for logistics and equipment maintenance include:\n",
      "\n",
      "* Renting or purchasing equipment, such as microscopes, tools, or lab equipment\n",
      "* Setting up a safe and organized workspace for each activity\n",
      "* Ensuring that all materials are stored and disposed of properly\n",
      "* Budgeting for contingencies, such as unexpected equipment failures or material shortages\n",
      "\n",
      "Additionally, consider the potential impact on volunteers, facilitators, or staff involved in setting up and running the workshop. How will they be managed, supported, and supervised during the event?\n"
     ]
    }
   ],
   "source": [
    "###### Generic ToT Search ##########\n",
    "\n",
    "import re\n",
    "\n",
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "def propose_thoughts(question, state, k=2):\n",
    "    prompt = f\"\"\"You are exploring solutions.\n",
    "            Problem: {question}\n",
    "            Current partial solution: {state}\n",
    "\n",
    "            Propose at most {k} different next thoughts.\"\"\"\n",
    "    \n",
    "    r = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.9,\n",
    "        n=k\n",
    "    )\n",
    "    return [c.message.content.strip() for c in r.choices]\n",
    "\n",
    "\n",
    "def score_state(question, state):\n",
    "    prompt = f\"\"\"Problem: {question}\n",
    "        Rate from 1-10 how promising this partial solution is: {state}\"\"\"\n",
    "    \n",
    "    r = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    try:\n",
    "        return int(re.findall(r\"\\d+\", r.choices[0].message.content)[0])\n",
    "    except Exception:\n",
    "        return 5  # neutral fallback\n",
    "\n",
    "\n",
    "def tree_of_thoughts(question, depth=2, width=2):\n",
    "    frontier = [(\"\", 0)]\n",
    "    for _ in range(depth):\n",
    "        new_frontier = []\n",
    "        for state, _ in frontier:\n",
    "            for thought in propose_thoughts(question, state, k=width):\n",
    "                new_state = (state + \"\\n\" + thought).strip()\n",
    "                score = score_state(question, new_state)\n",
    "                new_frontier.append((new_state, score))\n",
    "        new_frontier.sort(key=lambda x: x[1], reverse=True)  # keep top‑k\n",
    "        frontier = new_frontier[:width]\n",
    "    best_state, best_score = frontier[0]\n",
    "    return best_state, best_score\n",
    "\n",
    "\n",
    "question = \"Design a plan for a weekend science workshop for 12-year-olds.\"\n",
    "solution, score = tree_of_thoughts(question)\n",
    "\n",
    "print(f\"Best solution (score {score}):\\n{solution}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc38f6",
   "metadata": {},
   "source": [
    "---  \n",
    "# 3‑ Training Models for Reasoning\n",
    "\n",
    "### 3.1: CoT Training\n",
    "Chain-of-Thought (CoT) training conditions the model on explicit rationales during fine-tuning. Instead of teaching the model to output only the final answer, we train on (question, rationale, answer) so the model learns to internalize multi-step reasoning patterns. A practical recipe is STaR (Self-Taught Reasoner), which uses a stronger teacher model to bootstrap rationales that a smaller student can learn from.\n",
    "\n",
    "For tasks that require multi-hop reasoning, models fine-tuned on rationales often achieve higher accuracy and are more stable at inference time than models trained on direct answers only. \n",
    "\n",
    "Training a full language model is beyond the scope of this notebook, but here is the high-level workflow followed by a short pseudocode:\n",
    "- Collect questions: Prepare a dataset of questions and correct answers.\n",
    "- Generate rationales: Use a strong LLM to produce step-by-step reasoning ending with the correct answer.\n",
    "- Filter and clean: Discard incorrect or low-quality rationales.\n",
    "- Prepare training data: Format triples (question, rationale, answer) for supervised fine-tuning.\n",
    "- Fine-tune: Fine-tune the LLM on rationales.\n",
    "- Iterate: Refine prompts, improve data quality, and retrain for stronger reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb7cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode (STaR loop)\n",
    "# for round in 1 ... iters:\n",
    "    # STEP 1: self-generate reasoning (teacher creates rationale + answer)\n",
    "    # STEP 2: keep only correct, high-quality traces\n",
    "    # STEP 3: fine-tune student on (question, rationale, answer) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b53c70",
   "metadata": {},
   "source": [
    "### 3.2: ORM vs PRM + RL\n",
    "Training a Reward Model (RM) allows large language models to be improved through reinforcement learning (RL). Instead of fine-tuning directly on examples, we train a separate model that can score or rank model outputs, and use those scores as feedback signals to refine the policy model.\n",
    "\n",
    "Two main reward modeling approaches are ORM (predicts a scalar reward for the final answer) and PRM (evaluates the reasoning steps instead of just the outcome)\n",
    "\n",
    "\n",
    "\n",
    "| Approach | Typical loss | When to use |\n",
    "|-----------|-------------|-------------|\n",
    "|*Outcome Reward Model* | Predict scalar reward | Easy to collect training data using verifiers |\n",
    "|*Process Reward Model* | Predict rewards per step | Difficult to collect training data but more accurate |\n",
    "| *RLHF* | Use RM as reward in **RL** fine‑tuning | Aligns policy with human signals | Aligns model policy with human or synthetic preferences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595635aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for round = 1 ... iters:\n",
    "    # STEP 1:  Generate reasoning\n",
    "        # sample a minibatch of questions\n",
    "        # policy roll‑out (actions + log‑probs)\n",
    "    # STEP 2:  Score the trajectory\n",
    "        # ORM: scalar reward for the final answer / PRM: scalar reward for the thought process\n",
    "    # STEP 3:  Reinforce the policy (PPO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545a81a6",
   "metadata": {},
   "source": [
    "---  \n",
    "# 4‑ A Deep Research Agent\n",
    "\n",
    "A deep-research agent pairs a reasoning model (e.g., deepseek-r1) with external tools for web search and retrieval. We will follow the ReAct pattern: the model writes short thoughts, decides when to call tools, reads observations, and continues reasoning until it can answer or reaches a step limit.\n",
    "\n",
    "We now combine a **search tool** with a reasoning model (e.g., `deepseek-r1`) in a multi-step setup. We follow the *ReAct* pattern (reason → tool → observation):\n",
    "\n",
    "1. The model reasoins and decides to use tools\n",
    "2. The agent searches and feed condensed snippets back as context\n",
    "3. Iterate until the model answers or hits a step limit\n",
    "\n",
    "We use `AgentType.OPENAI_FUNCTIONS`, which hides the loop inside the LangChain agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd1e1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddgs import DDGS\n",
    "from langchain.tools import Tool\n",
    "\n",
    "\n",
    "def ddg_search(query: str, k: int = 5) -> str:\n",
    "    \"\"\"Basic DuckDuckGo web search that returns a concatenated text snippet.\"\"\"\n",
    "    with DDGS() as ddgs:\n",
    "        results = [hit[\"body\"] for hit in ddgs.text(query, max_results=k)]\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "search_tool = Tool(\n",
    "    name=\"DuckDuckGo Search\",\n",
    "    func=ddg_search,\n",
    "    description=\"Search the public web. Input: a plain English query. Returns: concatenated snippets.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "418a0d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cmiyachi\\AppData\\Local\\Temp\\ipykernel_44664\\499745259.py:8: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=MODEL, temperature=0.2)\n",
      "C:\\Users\\cmiyachi\\AppData\\Local\\Temp\\ipykernel_44664\\499745259.py:11: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Okay, predicting the \"best\" resources in 2025 requires understanding current trends and assuming they will evolve, rather than suddenly disappear. The core concepts of Machine Learning (ML) remain constant, but the *delivery* and *tools* will likely change.\n",
      "\n",
      "Here's a breakdown of resources, focusing on those likely to be prominent or foundational in 2025:\n",
      "\n",
      "## I. Foundational Knowledge (Essential - Won't Change Dramatically)\n",
      "\n",
      "1.  **Core Concepts:** Probability, Statistics, Linear Algebra, Calculus, Python programming.\n",
      "    *   **Resource Type:** Textbooks, Online Courses (Introductory).\n",
      "    *   **Examples (Likely Evolving but Still Foundational):**\n",
      "        *   *Introductory Python for Data Science and Machine Learning:* *Python for Data Analysis* (Wes McKinney), *Python Data Science Handbook* (Jake VanderPlas) - likely updated editions.\n",
      "        *   *Statistics & Probability:* *Statistical Learning with R* (Gareth James et al.) concepts will transfer to Python, or updated online courses.\n",
      "        *   *Linear Algebra:* Online courses (like those on edX, Coursera) focusing on ML applications will likely persist.\n",
      "\n",
      "## II. Learning Platforms & Courses (Likely to Evolve)\n",
      "\n",
      "1.  **University Courses (Online):**\n",
      "    *   **Resource Type:** Structured courses from top universities (Coursera, edX, Udacity).\n",
      "    *   **Why it's relevant in 2025:** Deep pedagogy, foundational understanding, often covers newer topics (like deep learning, reinforcement learning).\n",
      "    *   **Examples:** Andrew Ng's courses (likely updated versions on Coursera/DeepLearning.AI), Stanford's CS229 (likely available on platforms like YouTube/edX), MIT's courses.\n",
      "2.  **Specialized MOOCs (Massive Open Online Courses):**\n",
      "    *   **Resource Type:** Focused courses on specific ML areas.\n",
      "    *   **Examples:** Google's ML courses (e.g., TensorFlow Developer Certificate), fast.ai (practical deep learning), Berkeley's CS295 (Reinforcement Learning), OpenAIMinds courses.\n",
      "3.  **Interactive Coding Platforms:**\n",
      "    *   **Resource Type:** Hands-on coding exercises.\n",
      "    *   **Examples:** Google Colab (free GPU access, likely evolving with more features), Kaggle Kernels, Jupyter notebooks integrated into courses.\n",
      "4.  **YouTube Channels & Tutorials:**\n",
      "    *   **Resource Type:** Visual explanations, quick dives, community discussions.\n",
      "    *   **Examples:** Google AI, PyTorch, TensorFlow, 3Blue1Brown (for intuition), Kaggle tutorials, specific YouTubers (like Sentdex, CoreML - though quality varies).\n",
      "\n",
      "## III. Hands-On Practice & Community\n",
      "\n",
      "1.  **Kaggle:**\n",
      "    *   **Resource Type:** Competitions, datasets, notebooks, discussion forums.\n",
      "    *   **Why relevant in 2025:** Crucial for practical application, portfolio building, staying updated with real-world problems. The platform itself will likely evolve (better tools, more datasets).\n",
      "2.  **GitHub:**\n",
      "    *   **Resource Type:** Finding open-source ML projects, contributing, learning best practices.\n",
      "    *   **Why relevant:** Shows real-world code implementation, collaboration, understanding software engineering aspects of ML.\n",
      "3.  **Personal Projects:**\n",
      "    *   **Resource Type:** Building your own ML applications.\n",
      "    *   **Why relevant:** The most effective way to learn and demonstrate skills. Focus on problems you're passionate about.\n",
      "\n",
      "## IV. Staying Updated\n",
      "\n",
      "1.  **Documentation & Official Sources:**\n",
      "    *   **Resource Type:** Official documentation for libraries (TensorFlow, PyTorch, Scikit-learn, etc.).\n",
      "    *   **Why relevant:** The primary source for learning *how* to use specific tools. Libraries will evolve, so documentation is key.\n",
      "2.  **Blogs & Technical Websites:**\n",
      "    *   **Resource Type:** Tutorials, news, opinion pieces.\n",
      "    *   **Examples:** Towards Data Science (likely evolving format), ML Ops Blog, Kaggle Blog, official library blogs.\n",
      "3.  **Research Papers (arXiv):**\n",
      "    *   **Resource Type:** Cutting-edge research.\n",
      "    *   **Why relevant:** To understand the *latest* advancements. Learning how to read and understand papers will be crucial. Tools like arXiv will likely remain central.\n",
      "4.  **Podcasts & Newsletters:**\n",
      "    *   **Resource Type:** Curated summaries, interviews, news.\n",
      "    *   **Examples:** Machine Learning Mastery Newsletter, various AI/ML podcasts (e.g., TWIML AI, Machine Learning Street Talk).\n",
      "\n",
      "## Key Considerations for 2025\n",
      "\n",
      "*   **Focus on Fundamentals:** Don't get lost in the hype of the latest tool; solid math and theory are essential.\n",
      "*   **Embrace Open Source:** Libraries like TensorFlow, PyTorch, Scikit-learn will likely remain dominant and evolve.\n",
      "*   **Practical Application:** Kaggle, personal projects, and contributing to open-source will be vital.\n",
      "*   **Ethics and Responsible AI:** This will be a growing focus, likely integrated into more courses and discussions.\n",
      "*   **Adaptability:** The landscape changes fast. Curiosity, critical thinking, and the ability to learn new tools quickly will be paramount.\n",
      "\n",
      "**In summary:** The best resources in 2025 will likely build upon the current foundations but evolve in delivery (more interactive, integrated platforms, better documentation), tools (evolving ML libraries), and focus (increased emphasis on ethics, practical application, and staying current with research). Prioritize learning the core concepts deeply and then applying them through hands-on practice and continuous learning.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Okay, predicting the \"best\" resources in 2025 requires understanding current trends and assuming they will evolve, rather than suddenly disappear. The core concepts of Machine Learning (ML) remain constant, but the *delivery* and *tools* will likely change.\n",
      "\n",
      "Here's a breakdown of resources, focusing on those likely to be prominent or foundational in 2025:\n",
      "\n",
      "## I. Foundational Knowledge (Essential - Won't Change Dramatically)\n",
      "\n",
      "1.  **Core Concepts:** Probability, Statistics, Linear Algebra, Calculus, Python programming.\n",
      "    *   **Resource Type:** Textbooks, Online Courses (Introductory).\n",
      "    *   **Examples (Likely Evolving but Still Foundational):**\n",
      "        *   *Introductory Python for Data Science and Machine Learning:* *Python for Data Analysis* (Wes McKinney), *Python Data Science Handbook* (Jake VanderPlas) - likely updated editions.\n",
      "        *   *Statistics & Probability:* *Statistical Learning with R* (Gareth James et al.) concepts will transfer to Python, or updated online courses.\n",
      "        *   *Linear Algebra:* Online courses (like those on edX, Coursera) focusing on ML applications will likely persist.\n",
      "\n",
      "## II. Learning Platforms & Courses (Likely to Evolve)\n",
      "\n",
      "1.  **University Courses (Online):**\n",
      "    *   **Resource Type:** Structured courses from top universities (Coursera, edX, Udacity).\n",
      "    *   **Why it's relevant in 2025:** Deep pedagogy, foundational understanding, often covers newer topics (like deep learning, reinforcement learning).\n",
      "    *   **Examples:** Andrew Ng's courses (likely updated versions on Coursera/DeepLearning.AI), Stanford's CS229 (likely available on platforms like YouTube/edX), MIT's courses.\n",
      "2.  **Specialized MOOCs (Massive Open Online Courses):**\n",
      "    *   **Resource Type:** Focused courses on specific ML areas.\n",
      "    *   **Examples:** Google's ML courses (e.g., TensorFlow Developer Certificate), fast.ai (practical deep learning), Berkeley's CS295 (Reinforcement Learning), OpenAIMinds courses.\n",
      "3.  **Interactive Coding Platforms:**\n",
      "    *   **Resource Type:** Hands-on coding exercises.\n",
      "    *   **Examples:** Google Colab (free GPU access, likely evolving with more features), Kaggle Kernels, Jupyter notebooks integrated into courses.\n",
      "4.  **YouTube Channels & Tutorials:**\n",
      "    *   **Resource Type:** Visual explanations, quick dives, community discussions.\n",
      "    *   **Examples:** Google AI, PyTorch, TensorFlow, 3Blue1Brown (for intuition), Kaggle tutorials, specific YouTubers (like Sentdex, CoreML - though quality varies).\n",
      "\n",
      "## III. Hands-On Practice & Community\n",
      "\n",
      "1.  **Kaggle:**\n",
      "    *   **Resource Type:** Competitions, datasets, notebooks, discussion forums.\n",
      "    *   **Why relevant in 2025:** Crucial for practical application, portfolio building, staying updated with real-world problems. The platform itself will likely evolve (better tools, more datasets).\n",
      "2.  **GitHub:**\n",
      "    *   **Resource Type:** Finding open-source ML projects, contributing, learning best practices.\n",
      "    *   **Why relevant:** Shows real-world code implementation, collaboration, understanding software engineering aspects of ML.\n",
      "3.  **Personal Projects:**\n",
      "    *   **Resource Type:** Building your own ML applications.\n",
      "    *   **Why relevant:** The most effective way to learn and demonstrate skills. Focus on problems you're passionate about.\n",
      "\n",
      "## IV. Staying Updated\n",
      "\n",
      "1.  **Documentation & Official Sources:**\n",
      "    *   **Resource Type:** Official documentation for libraries (TensorFlow, PyTorch, Scikit-learn, etc.).\n",
      "    *   **Why relevant:** The primary source for learning *how* to use specific tools. Libraries will evolve, so documentation is key.\n",
      "2.  **Blogs & Technical Websites:**\n",
      "    *   **Resource Type:** Tutorials, news, opinion pieces.\n",
      "    *   **Examples:** Towards Data Science (likely evolving format), ML Ops Blog, Kaggle Blog, official library blogs.\n",
      "3.  **Research Papers (arXiv):**\n",
      "    *   **Resource Type:** Cutting-edge research.\n",
      "    *   **Why relevant:** To understand the *latest* advancements. Learning how to read and understand papers will be crucial. Tools like arXiv will likely remain central.\n",
      "4.  **Podcasts & Newsletters:**\n",
      "    *   **Resource Type:** Curated summaries, interviews, news.\n",
      "    *   **Examples:** Machine Learning Mastery Newsletter, various AI/ML podcasts (e.g., TWIML AI, Machine Learning Street Talk).\n",
      "\n",
      "## Key Considerations for 2025\n",
      "\n",
      "*   **Focus on Fundamentals:** Don't get lost in the hype of the latest tool; solid math and theory are essential.\n",
      "*   **Embrace Open Source:** Libraries like TensorFlow, PyTorch, Scikit-learn will likely remain dominant and evolve.\n",
      "*   **Practical Application:** Kaggle, personal projects, and contributing to open-source will be vital.\n",
      "*   **Ethics and Responsible AI:** This will be a growing focus, likely integrated into more courses and discussions.\n",
      "*   **Adaptability:** The landscape changes fast. Curiosity, critical thinking, and the ability to learn new tools quickly will be paramount.\n",
      "\n",
      "**In summary:** The best resources in 2025 will likely build upon the current foundations but evolve in delivery (more interactive, integrated platforms, better documentation), tools (evolving ML libraries), and focus (increased emphasis on ethics, practical application, and staying current with research). Prioritize learning the core concepts deeply and then applying them through hands-on practice and continuous learning.\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Okay, predicting the \"best\" resources in 2025 requires understanding current trends and assuming they will evolve, rather than suddenly disappear. The core concepts of Machine Learning (ML) remain constant, but the *delivery* and *tools* will likely change.\n",
      "\n",
      "Here's a breakdown of resources, focusing on those likely to be prominent or foundational in 2025:\n",
      "\n",
      "## I. Foundational Knowledge (Essential - Won't Change Dramatically)\n",
      "\n",
      "1.  **Core Concepts:** Probability, Statistics, Linear Algebra, Calculus, Python programming.\n",
      "    *   **Resource Type:** Textbooks, Online Courses (Introductory).\n",
      "    *   **Examples (Likely Evolving but Still Foundational):**\n",
      "        *   *Introductory Python for Data Science and Machine Learning:* *Python for Data Analysis* (Wes McKinney), *Python Data Science Handbook* (Jake VanderPlas) - likely updated editions.\n",
      "        *   *Statistics & Probability:* *Statistical Learning with R* (Gareth James et al.) concepts will transfer to Python, or updated online courses.\n",
      "        *   *Linear Algebra:* Online courses (like those on edX, Coursera) focusing on ML applications will likely persist.\n",
      "\n",
      "## II. Learning Platforms & Courses (Likely to Evolve)\n",
      "\n",
      "1.  **University Courses (Online):**\n",
      "    *   **Resource Type:** Structured courses from top universities (Coursera, edX, Udacity).\n",
      "    *   **Why it's relevant in 2025:** Deep pedagogy, foundational understanding, often covers newer topics (like deep learning, reinforcement learning).\n",
      "    *   **Examples:** Andrew Ng's courses (likely updated versions on Coursera/DeepLearning.AI), Stanford's CS229 (likely available on platforms like YouTube/edX), MIT's courses.\n",
      "2.  **Specialized MOOCs (Massive Open Online Courses):**\n",
      "    *   **Resource Type:** Focused courses on specific ML areas.\n",
      "    *   **Examples:** Google's ML courses (e.g., TensorFlow Developer Certificate), fast.ai (practical deep learning), Berkeley's CS295 (Reinforcement Learning), OpenAIMinds courses.\n",
      "3.  **Interactive Coding Platforms:**\n",
      "    *   **Resource Type:** Hands-on coding exercises.\n",
      "    *   **Examples:** Google Colab (free GPU access, likely evolving with more features), Kaggle Kernels, Jupyter notebooks integrated into courses.\n",
      "4.  **YouTube Channels & Tutorials:**\n",
      "    *   **Resource Type:** Visual explanations, quick dives, community discussions.\n",
      "    *   **Examples:** Google AI, PyTorch, TensorFlow, 3Blue1Brown (for intuition), Kaggle tutorials, specific YouTubers (like Sentdex, CoreML - though quality varies).\n",
      "\n",
      "## III. Hands-On Practice & Community\n",
      "\n",
      "1.  **Kaggle:**\n",
      "    *   **Resource Type:** Competitions, datasets, notebooks, discussion forums.\n",
      "    *   **Why relevant in 2025:** Crucial for practical application, portfolio building, staying updated with real-world problems. The platform itself will likely evolve (better tools, more datasets).\n",
      "2.  **GitHub:**\n",
      "    *   **Resource Type:** Finding open-source ML projects, contributing, learning best practices.\n",
      "    *   **Why relevant:** Shows real-world code implementation, collaboration, understanding software engineering aspects of ML.\n",
      "3.  **Personal Projects:**\n",
      "    *   **Resource Type:** Building your own ML applications.\n",
      "    *   **Why relevant:** The most effective way to learn and demonstrate skills. Focus on problems you're passionate about.\n",
      "\n",
      "## IV. Staying Updated\n",
      "\n",
      "1.  **Documentation & Official Sources:**\n",
      "    *   **Resource Type:** Official documentation for libraries (TensorFlow, PyTorch, Scikit-learn, etc.).\n",
      "    *   **Why relevant:** The primary source for learning *how* to use specific tools. Libraries will evolve, so documentation is key.\n",
      "2.  **Blogs & Technical Websites:**\n",
      "    *   **Resource Type:** Tutorials, news, opinion pieces.\n",
      "    *   **Examples:** Towards Data Science (likely evolving format), ML Ops Blog, Kaggle Blog, official library blogs.\n",
      "3.  **Research Papers (arXiv):**\n",
      "    *   **Resource Type:** Cutting-edge research.\n",
      "    *   **Why relevant:** To understand the *latest* advancements. Learning how to read and understand papers will be crucial. Tools like arXiv will likely remain central.\n",
      "4.  **Podcasts & Newsletters:**\n",
      "    *   **Resource Type:** Curated summaries, interviews, news.\n",
      "    *   **Examples:** Machine Learning Mastery Newsletter, various AI/ML podcasts (e.g., TWIML AI, Machine Learning Street Talk).\n",
      "\n",
      "## Key Considerations for 2025\n",
      "\n",
      "*   **Focus on Fundamentals:** Don't get lost in the hype of the latest tool; solid math and theory are essential.\n",
      "*   **Embrace Open Source:** Libraries like TensorFlow, PyTorch, Scikit-learn will likely remain dominant and evolve.\n",
      "*   **Practical Application:** Kaggle, personal projects, and contributing to open-source will be vital.\n",
      "*   **Ethics and Responsible AI:** This will be a growing focus, likely integrated into more courses and discussions.\n",
      "*   **Adaptability:** The landscape changes fast. Curiosity, critical thinking, and the ability to learn new tools quickly will be paramount.\n",
      "\n",
      "**In summary:** The best resources in 2025 will likely build upon the current foundations but evolve in delivery (more interactive, integrated platforms, better documentation), tools (evolving ML libraries), and focus (increased emphasis on ethics, practical application, and staying current with research). Prioritize learning the core concepts deeply and then applying them through hands-on practice and continuous learning.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Okay, predicting the \"best\" resources in 2025 requires understanding current trends and assuming they will evolve, rather than suddenly disappear. The core concepts of Machine Learning (ML) remain constant, but the *delivery* and *tools* will likely change.\n",
      "\n",
      "Here's a breakdown of resources, focusing on those likely to be prominent or foundational in 2025:\n",
      "\n",
      "## I. Foundational Knowledge (Essential - Won't Change Dramatically)\n",
      "\n",
      "1.  **Core Concepts:** Probability, Statistics, Linear Algebra, Calculus, Python programming.\n",
      "    *   **Resource Type:** Textbooks, Online Courses (Introductory).\n",
      "    *   **Examples (Likely Evolving but Still Foundational):**\n",
      "        *   *Introductory Python for Data Science and Machine Learning:* *Python for Data Analysis* (Wes McKinney), *Python Data Science Handbook* (Jake VanderPlas) - likely updated editions.\n",
      "        *   *Statistics & Probability:* *Statistical Learning with R* (Gareth James et al.) concepts will transfer to Python, or updated online courses.\n",
      "        *   *Linear Algebra:* Online courses (like those on edX, Coursera) focusing on ML applications will likely persist.\n",
      "\n",
      "## II. Learning Platforms & Courses (Likely to Evolve)\n",
      "\n",
      "1.  **University Courses (Online):**\n",
      "    *   **Resource Type:** Structured courses from top universities (Coursera, edX, Udacity).\n",
      "    *   **Why it's relevant in 2025:** Deep pedagogy, foundational understanding, often covers newer topics (like deep learning, reinforcement learning).\n",
      "    *   **Examples:** Andrew Ng's courses (likely updated versions on Coursera/DeepLearning.AI), Stanford's CS229 (likely available on platforms like YouTube/edX), MIT's courses.\n",
      "2.  **Specialized MOOCs (Massive Open Online Courses):**\n",
      "    *   **Resource Type:** Focused courses on specific ML areas.\n",
      "    *   **Examples:** Google's ML courses (e.g., TensorFlow Developer Certificate), fast.ai (practical deep learning), Berkeley's CS295 (Reinforcement Learning), OpenAIMinds courses.\n",
      "3.  **Interactive Coding Platforms:**\n",
      "    *   **Resource Type:** Hands-on coding exercises.\n",
      "    *   **Examples:** Google Colab (free GPU access, likely evolving with more features), Kaggle Kernels, Jupyter notebooks integrated into courses.\n",
      "4.  **YouTube Channels & Tutorials:**\n",
      "    *   **Resource Type:** Visual explanations, quick dives, community discussions.\n",
      "    *   **Examples:** Google AI, PyTorch, TensorFlow, 3Blue1Brown (for intuition), Kaggle tutorials, specific YouTubers (like Sentdex, CoreML - though quality varies).\n",
      "\n",
      "## III. Hands-On Practice & Community\n",
      "\n",
      "1.  **Kaggle:**\n",
      "    *   **Resource Type:** Competitions, datasets, notebooks, discussion forums.\n",
      "    *   **Why relevant in 2025:** Crucial for practical application, portfolio building, staying updated with real-world problems. The platform itself will likely evolve (better tools, more datasets).\n",
      "2.  **GitHub:**\n",
      "    *   **Resource Type:** Finding open-source ML projects, contributing, learning best practices.\n",
      "    *   **Why relevant:** Shows real-world code implementation, collaboration, understanding software engineering aspects of ML.\n",
      "3.  **Personal Projects:**\n",
      "    *   **Resource Type:** Building your own ML applications.\n",
      "    *   **Why relevant:** The most effective way to learn and demonstrate skills. Focus on problems you're passionate about.\n",
      "\n",
      "## IV. Staying Updated\n",
      "\n",
      "1.  **Documentation & Official Sources:**\n",
      "    *   **Resource Type:** Official documentation for libraries (TensorFlow, PyTorch, Scikit-learn, etc.).\n",
      "    *   **Why relevant:** The primary source for learning *how* to use specific tools. Libraries will evolve, so documentation is key.\n",
      "2.  **Blogs & Technical Websites:**\n",
      "    *   **Resource Type:** Tutorials, news, opinion pieces.\n",
      "    *   **Examples:** Towards Data Science (likely evolving format), ML Ops Blog, Kaggle Blog, official library blogs.\n",
      "3.  **Research Papers (arXiv):**\n",
      "    *   **Resource Type:** Cutting-edge research.\n",
      "    *   **Why relevant:** To understand the *latest* advancements. Learning how to read and understand papers will be crucial. Tools like arXiv will likely remain central.\n",
      "4.  **Podcasts & Newsletters:**\n",
      "    *   **Resource Type:** Curated summaries, interviews, news.\n",
      "    *   **Examples:** Machine Learning Mastery Newsletter, various AI/ML podcasts (e.g., TWIML AI, Machine Learning Street Talk).\n",
      "\n",
      "## Key Considerations for 2025\n",
      "\n",
      "*   **Focus on Fundamentals:** Don't get lost in the hype of the latest tool; solid math and theory are essential.\n",
      "*   **Embrace Open Source:** Libraries like TensorFlow, PyTorch, Scikit-learn will likely remain dominant and evolve.\n",
      "*   **Practical Application:** Kaggle, personal projects, and contributing to open-source will be vital.\n",
      "*   **Ethics and Responsible AI:** This will be a growing focus, likely integrated into more courses and discussions.\n",
      "*   **Adaptability:** The landscape changes fast. Curiosity, critical thinking, and the ability to learn new tools quickly will be paramount.\n",
      "\n",
      "**In summary:** The best resources in 2025 will likely build upon the current foundations but evolve in delivery (more interactive, integrated platforms, better documentation), tools (evolving ML libraries), and focus (increased emphasis on ethics, practical application, and staying current with research). Prioritize learning the core concepts deeply and then applying them through hands-on practice and continuous learning.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "MODEL = \"deepseek-r1:8b\"\n",
    "question = \"What are the best resources to learn machine learning in 2025?\"\n",
    "\n",
    "# Step 1: Initialize the reasoning model via ChatOllama\n",
    "llm = ChatOllama(model=MODEL, temperature=0.2)\n",
    "\n",
    "# Step 2: Build the agent with tool access (DuckDuckGo Search) and function-calling interface (initialize_agent)\n",
    "agent = initialize_agent(\n",
    "    tools=[search_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Step 3: Ask a query and let the agent search + reason to produce an answer\n",
    "result = agent.invoke({\"input\": question})\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b1c3f7",
   "metadata": {},
   "source": [
    "# Optional (Multi-agent Deep Research)\n",
    "Instead of a single multi-step agent, you can design multiple collaborating agents such as a Planner, Searcher, Summarizer, and Verifier that pass information and refine each other’s outputs. This setup improves robustness, diversity of reasoning, and division of labor.\n",
    "\n",
    "Try building a simple setup with 2–3 agents that share goals and messages, for example Planner → Researcher → Writer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d59abf94",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m    YOUR CODE HERE\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m      8\u001b[39m answers = parallel_research(\u001b[33m\"\u001b[39m\u001b[33mWhat are the best resources to learn ML in 2025?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i,a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43manswers\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma[:\u001b[32m200\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m…\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "def parallel_research(query, n=3):\n",
    "    # Run n independent research runs in parallel and return their answers.\n",
    "    # Steps: use ThreadPoolExecutor; submit n calls to your agent/search pipeline; gather results in order.\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE\n",
    "    \"\"\"\n",
    "\n",
    "answers = parallel_research(\"What are the best resources to learn ML in 2025?\")\n",
    "for i,a in enumerate(answers,1):\n",
    "    print(f\"[Run {i}] {a[:200]}…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9507d0a4",
   "metadata": {},
   "source": [
    "## 🎉 Congratulations!\n",
    "\n",
    "* Practised various inference‑time reasoning methods\n",
    "* Gained intuition about training reasoning models\n",
    "* You have built a **deep-research agent**: reasoning model like deep-seek r1 + ReAct-style agent + tool use (web search)\n",
    "* Try adding more tools, and extending the deep-research to a multi-agent system: many agents researching web in parallel.\n",
    "\n",
    "\n",
    "👏 **Great job!** Take a moment to celebrate. The techniques you implemented here power many production agents and chatbots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
